# S3 101
1. **Introduction to S3**:
    - S3 stands for Simple Storage Service, providing secure, durable, and scalable object storage for files, images, web pages, etc.
    - It's easy to use with a web services interface, highly scalable, and cost-effective for storing and retrieving data.
2. **Object Storage**:
    - S3 manages data as objects rather than in file systems or data blocks.
    - You can upload various file types like photos, videos, code, documents, but not for running an operating system or a database.
3. **Unlimited Storage**:
    - S3 offers unlimited storage capacity, so you don't need to worry about space allocation or predicting storage needs.
4. **Buckets**:
    - Files in S3 are stored in buckets, which are similar to folders and have globally unique names.
5. **URL Structure**:
    - S3 URLs consist of the bucket name, region, and object name (key).
6. **Key-Value Store**:
    - S3 objects include a key (object name), value (data bytes), version ID (for multiple versions), and metadata (additional information about the data).
7. **Availability and Durability**:
    - S3 is highly available (99.95% to 99.99% uptime) and durable (11 nines durability for data).
    - Data is spread across multiple devices and facilities for availability and protection against loss or corruption.
8. **Tiered Storage and Lifecycle Management**:
    - S3 offers tiered storage for different use cases and lifecycle management to automate object transitions or deletions based on rules.
9. **Security**:
    - Server-side encryption, access control lists (ACLs), and bucket policies ensure data security and access control.
10. **Exam Tips**:
    - S3 is object-based, suitable for storing files up to 5 terabytes, with unlimited storage capacity.
    - Files are stored in buckets with globally unique names, and successful uploads generate an HTTP 200 status code.

[Amazon S3 FAQs](https://aws.amazon.com/s3/faqs/)

[Amazon S3 Performance Tips & Tricks + Seattle S3 Hiring Event](https://aws.amazon.com/blogs/aws/amazon-s3-performance-tips-tricks-seattle-hiring-event/)

[Sharing an object with a presigned URL](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html)

# Reviewing S3 Storage Classes
1. **S3 Standard**:
    - Designed for high availability and durability, suitable for frequently accessed data like websites, content distribution, and big data analytics.
    - 99.99% availability and 11 nines durability.
    - Default storage class.
2. **S3 Standard Infrequent Access (S3-IA)**:
    - For infrequently accessed data with rapid access requirements.
    - Lower storage cost but with per gigabyte retrieval fees.
    - Use cases include long-term storage, backups, and disaster recovery files.
3. **One Zone-Infrequent Access**:
    - Similar to S3-IA but data is stored redundantly within a single availability zone, making it cost-effective.
    - Suitable for long-lived, infrequently accessed non-critical data.
4. **Glacier**:
    - Very cheap and optimized for very infrequently accessed data.
    - Pay per access with retrieval times ranging from one minute to 12 hours.
    - Ideal for historical data or archives accessed a few times a year.
5. **Glacier Deep Archive**:
    - For archiving rarely accessed data with a default retrieval time of 12 hours.
    - Minimum storage duration of 180 days, suitable for data accessed once or twice per year.
6. **Intelligent-Tiering**:
    - Automatically moves data between frequent and infrequent access tiers based on usage patterns.
    - Helps optimize costs with a small additional fee per 1,000 objects.
    - Suitable for unpredictable access patterns.

Remember, S3 Standard is suitable for most workloads, S3-IA for infrequently accessed data, One Zone-IA for non-critical data, Glacier for long-term archiving, Glacier Deep Archive for rarely accessed data, and Intelligent-Tiering for unknown access patterns. Understanding the use cases and differences is important for choosing the right storage class in Amazon S3.

[Amazon S3 Storage Classes](https://aws.amazon.com/s3/storage-classes/)

[Amazon S3 Glacier storage classes](https://aws.amazon.com/s3/storage-classes/glacier/)

[Announcing the new Amazon S3 Glacier Instant Retrieval storage class - the lowest cost archive storage with milliseconds retrieval](https://aws.amazon.com/about-aws/whats-new/2021/11/amazon-s3-glacier-instant-retrieval-storage-class/)

# Securing S3 Buckets
1. **Default Security**:
    - Newly created S3 buckets are private by default, accessible only to the bucket owner.
    - No public access or anonymous access by default.
2. **Bucket Policies**:
    - Used to grant access to other AWS users or even anonymous users for read or read-write access to S3 buckets.
    - Applied at the bucket level and apply permissions to all objects within the bucket.
    - Written in JSON format and can provide blanket control over all objects in the bucket.
3. **Bucket Access Control Lists (Bucket ACLs)**:
    - Applied at the object level, allowing different permissions for different objects within the same bucket.
    - Provides fine-grained access control, granting read, write, or full control access to specific objects for different users or groups.
    - Enables setting some objects as publicly readable while others are restricted to specific users or groups.
4. **S3 Access Logs**:
    - Logs all requests made to S3 buckets, including uploads, reads, and deletions.
    - Not enabled by default but can be enabled to track and monitor access to S3 buckets.
    - Access logs can be written to another S3 bucket for analysis and auditing purposes.

Exam Tips:

- S3 buckets are secure by default, with private access.
- Use bucket policies for blanket control at the bucket level.
- Utilize bucket ACLs for fine-grained access control at the object level.
- Enable S3 access logs to monitor and track access to your S3 buckets.
- Access logs are not enabled by default and need to be configured manually.

Understanding these mechanisms is crucial for securing objects and buckets within Amazon S3.

[Sharing objects with presigned URLs](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html)

# Demo - S3 Bucket Policies
1. **Creating an S3 Bucket**:
    - Start by giving the bucket a DNS-compliant, globally unique name.
    - Choose the region and configure public access settings, which are blocked by default.
    - Optionally enable bucket versioning to keep multiple versions of objects.
    - Tags can be added to track projects or team costs.
2. **Encryption**:
    - By default, S3 applies server-side encryption (SSE-S3) to new buckets and objects.
    - SSE-KMS, using the Key Management Service, is another option for managing encryption keys.
3. **Uploading a File**:
    - Upload a file from your local machine to the S3 bucket.
4. **Accessing the File**:
    - Access the file through the console or as an unauthenticated user over the internet using the object URL.
5. **Enabling Public Access**:
    - Edit block public access settings to allow public access.
    - Create a bucket policy using the policy generator to allow GetObject action for public access.
    - Paste the generated policy into the bucket policy settings and save changes.
    - Refresh the page to confirm public access is allowed.

Exam Tips:

- Default S3 buckets are private with no public access.
- Use bucket policies to control access to objects within the bucket.
- Remember to disable block public access settings when enabling public access.
- Understand encryption options and how to manage access control settings for S3 buckets.

This lesson provides a step-by-step guide to creating an S3 bucket, uploading files, enabling public access, and managing access control using bucket policies.

# Lab - Create a Static Website Using Amazon S3

![AWS Cloud](Images/4.1.png)

# S3 Encryption
1. **Why Encrypt Data**:
    - Data protection is crucial for safeguarding valuable business assets like financial data, customer information, and proprietary code.
    - Encryption ensures data is secure and protected against unauthorized access.
2. **S3 Encryption Options**:
    - Encryption in transit using SSL/TLS protocols, ensuring secure communication over networks.
    - Encryption at rest (server-side encryption) with three options:
        - SSE-S3 (default): Uses S3-managed encryption keys and AES 256-bit encryption.
        - SSE-KMS: Utilizes encryption keys managed by AWS Key Management Service, suitable for regulatory compliance.
        - SSE-C: Allows customers to use their own encryption keys managed outside of AWS.
    - Client-side encryption: Encrypt files before uploading them to S3.
3. **Exam Tips**:
    - Understand encryption in transit (SSL/TLS) for secure communication over networks.
    - Server-side encryption options: SSE-S3 (default), SSE-KMS, and SSE-C.
    - Client-side encryption: Encrypt files before uploading to S3.
    - Remember that SSE-S3 is enabled by default when creating an S3 bucket or uploading objects.

This lesson provides insights into S3 encryption options, emphasizing the importance of securing data both in transit and at rest.

[AWS - S3 encryption update](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html#bucket-encryption-update-bucket-policy)

# Demo - Configuring Encryption on an S3 Bucket
1. **Creating an S3 Bucket**:
    - Created a bucket named "My Encrypted Files" with default encryption enabled (SSE-S3, S3 managed keys).
2. **Reviewing Encryption Options**:
    - Discussed server-side encryption options in S3:
        - SSE-S3 (default): Uses S3 managed keys for encryption.
        - SSE-KMS: Utilizes AWS Key Management Service for encryption keys.
        - SSE-C: Allows using customer-provided keys.
        - Client-side encryption: Encrypt files before uploading to S3.
3. **Configuring SSE-KMS Encryption**:
    - Selected AWS Key Management Service (KMS) as the encryption type for the bucket.
    - Created a new KMS key called "My KMS Key" for encrypting and decrypting files.
    - Defined key administrator and key user roles for managing and using the KMS key.
4. **Exam Tips**:
    - Understand encryption in transit (SSL/TLS) for secure communication.
    - Know the server-side encryption options: SSE-S3, SSE-KMS, and SSE-C.
    - Understand client-side encryption and its use case.

Remember, encryption is crucial for protecting data both in transit and at rest, and S3 provides various options to meet different security requirements.

[Protecting Data Using Server-Side Encryption](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html)

# Demo - CORS Configuration
1. **Setting Up S3 Buckets**:
    - Created two S3 buckets: "my index bucket" for hosting index.html and "my CORS test bucket" for hosting loadpage.html.
    - Configured public access and enabled static website hosting for both buckets.
2. **Updating Bucket Policies**:
    - Updated bucket policies to allow public access for hosting websites.
    - Used the Policy Generator to create bucket policies allowing GetObject actions for accessing objects in the buckets.
3. **Testing Website Access**:
    - Uploaded index.html and error.html to "my index bucket" and loadpage.html to "my CORS test bucket."
    - Accessed the index.html page to verify successful hosting.
4. **Configuring CORS**:
    - Added CORS configuration to "my CORS test bucket" to allow resources in one bucket to access resources in another bucket.
    - Updated CORS configuration with the URL of the "my index bucket" to allow access from that origin.
5. **Verifying CORS Configuration**:
    - Tested access to loadpage.html from index.html after configuring CORS.
    - Checked for CORS-related error messages in the browser's developer tools console to ensure proper CORS setup.
6. **Final Verification**:
    - Verified that the website displays content from both buckets, indicating successful CORS configuration.

For the exam, remember that CORS in S3 allows resources in one bucket to access resources in another bucket, and proper CORS configuration is necessary for cross-origin access to work correctly.

[CORS - What is it](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing)

[CORS Demo Files](https://github.com/ACloudGuru-Resources/course-aws-certified-developer-associate/tree/main/CORS_Lab_Files)

# Overview of CloudFront
1. **What is CloudFront?**:
    - CloudFront is Amazon's Content Delivery Network (CDN).
    - It's a system of distributed servers that deliver web content with low latency and high data transfer speeds.
2. **Purpose of CloudFront**:
    - Improves website performance by speeding up the distribution of static and dynamic web content.
    - Caches content like HTML, JavaScript, images, videos, and web applications at edge locations.
    - Reduces network latency and improves responsiveness for users globally.
3. **Key Concepts**:
    - **Edge Locations**: Geographically dispersed data centers where content is cached.
    - **Origin**: Source of files that the distribution serves (S3 bucket, EC2 instance, load balancer, etc.).
    - **CloudFront Distribution**: Configuration settings for content distribution using CloudFront.
4. **CloudFront Benefits**:
    - Optimizes website performance for users worldwide by automatically routing requests to the nearest edge location.
    - Works seamlessly with AWS services like S3, EC2, load balancer, and Route 53.
    - Supports caching of objects with a default TTL (Time to Live) of one day.
5. **Integration with S3 Transfer Acceleration**:
    - CloudFront technology is used with S3 Transfer Acceleration to accelerate file uploads into S3 buckets.
    - Users can upload files to CloudFront edge locations, which then transfer them to S3 using optimized network paths.
6. **Exam Tips**:
    - Understand edge locations, origin, and CloudFront distribution concepts.
    - Edge locations are not just read-only and can be used for uploads (e.g., S3 Transfer Acceleration).
    - Objects are cached in CloudFront with a TTL, and clearing the cache incurs charges.

Overall, CloudFront improves website performance and user experience by caching content at edge locations and routing requests to the nearest location, reducing latency and enhancing responsiveness globally.

# Demo - Configuring Amazon CloudFront
1. **Creating an S3 Bucket**:
    - Create an S3 bucket in a location far from your region to demonstrate latency.
    - Upload an image to the bucket.
2. **Accessing S3 Object**:
    - Access the image directly from the S3 bucket to observe latency due to geographical distance.
3. **Setting up CloudFront Distribution**:
    - Create a CloudFront distribution in the AWS console.
    - Specify the S3 bucket as the origin.
    - Configure default cache behavior, viewer protocol policy, allowed HTTP methods, and other settings.
    - Set up geographic restrictions if needed.
4. **Accessing Content through CloudFront**:
    - Use the CloudFront distribution URL to access the image, which will be cached in edge locations for faster access.
    - Compare the response time between accessing the image through CloudFront and directly from S3.
5. **Additional Features**:
    - Set up invalidations to remove cached objects from CloudFront when content changes.
    - Understand CloudFront's integration with AWS services like AWS WAF for security and web application firewall features.
6. **Exam Tips**:
    - CloudFront is a content delivery network that speeds up the delivery of static content globally.
    - The origin is where original content is stored, such as an S3 bucket.
    - Users access content from local edge locations, improving performance compared to direct access to the origin.

The lesson demonstrates the benefits of using CloudFront to improve content delivery speed and user experience, especially for geographically dispersed users.

```Bucket Policy
{
  "Id": "Policy1675093308212",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1675093303975",
      "Action": [
        "s3:GetObject"
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::INSERT_YOUR_BUCKET_NAME/*",
      "Principal": "*"
    }
  ]
}
```

# Configuring CloudFront With Origin Access Identity
1. **Creating an S3 Bucket**:
    - Create an S3 bucket with public access enabled.
    - Upload an image file to the bucket.
2. **Setting up CloudFront Distribution**:
    - Create a CloudFront distribution with the S3 bucket as the origin.
    - Use an origin access identity (OAI) to restrict access to CloudFront only.
    - Update permissions on the S3 bucket to allow access only through CloudFront.
3. **Testing Access**:
    - Access the image using the CloudFront distribution URL to ensure it works.
    - Block public access at the bucket level to enforce access through CloudFront.
4. **Exam Tips**:
    - CloudFront speeds up content delivery globally.
    - Origin access identity restricts access to content, forcing users to use CloudFront URLs.
    - OAI is used to ensure all access goes through CloudFront, enhancing security and control.

The lecture demonstrates how to enhance security and control access to content using CloudFront with origin access identity.

[Serving private content with signed URLs and signed cookies](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html)

# Understanding CloudFront AllowedMethods
- **CloudFront AllowedMethods**: When creating a CloudFront distribution, you specify which HTTP methods the distribution will support.
- **Supported HTTP Methods**:
    - GET and HEAD: Read-only methods for reading data or inspecting resource headers.
    - GET, HEAD, and OPTIONS: Also read-only methods, including OPTIONS to find supported HTTP methods.
    - GET, HEAD, OPTIONS, PUT, POST, PATCH, and DELETE: Read and write methods for creating, updating, deleting data, and other operations.
- **Use Cases**:
    - GET: Reading data, like web pages.
    - HEAD: Inspecting resource headers without reading the body.
    - PUT: Creating or replacing resources, idempotent action.
    - PATCH: Partially modifying resources.
    - POST: Inserting data, non-idempotent action.
    - DELETE: Deleting data.
    - OPTIONS: Finding supported HTTP methods.
- **Choosing Methods**:
    - Choose based on what actions users need on your website.
    - Read-only options for static content, interactive websites need read and write methods.
- **Exam Tips**:
    - Understand the three options for CloudFront AllowedMethods.
    - Consider user actions on your website to choose the appropriate methods.
    - Restrict access at the origin level to control operations users can perform.

The lecture provides insights into selecting CloudFront AllowedMethods based on website interactivity and user actions.

[CloudFront API Reference](https://docs.aws.amazon.com/cloudfront/latest/APIReference/API_AllowedMethods.html)

# Introducing Athena
- **What is Athena?**: Athena is an interactive query service that allows you to run standard SQL queries on data stored in Amazon S3. It is serverless, meaning there's no need for provisioning infrastructure, and you pay per query and per terabyte scanned.
- **Use Cases**:
    - Querying log files stored in S3, such as elastic load balancer logs, S3 access logs, and CloudTrail logs.
    - Performing cost analysis using AWS cost and usage reports stored in S3.
    - Generating business reports and analyzing clickstream data stored in S3.
- **Exam Tips**:
    - Athena is a serverless interactive query service for querying S3 data with standard SQL.
    - It eliminates the need for complex ETL processes and integrates directly with data stored in S3.

To understand Athena fully, it's recommended to engage with hands-on practice in the next lecture.

# Demo - Working with Athena
1. **Creating CloudTrail Trail**:
    - Create a CloudTrail trail named "management-events" to generate audit logs of user activity.
    - Configure the trail to store logs in a new S3 bucket.
2. **Creating Athena Database**:
    - Create an S3 bucket to store Athena query results.
    - Set up Athena's query result location to this bucket.
    - Create an Athena database named "athenadb" using a SQL query.
3. **Creating Athena Table**:
    - Create a table named "cloudtrail_logs" using a SQL command that defines attributes like user identity, account ID, event time, etc.
    - Specify the location of CloudTrail logs in the S3 bucket as the data source for this table.
4. **Querying Data with Athena**:
    - Use the Athena Query Editor to run SQL queries on the "cloudtrail_logs" table.
    - Example query retrieves user identity ARN, event name, source IP address, and event time from the logs.
5. **Exam Tips**:
    - Athena is a serverless, interactive query service for running SQL queries on data stored in S3.
    - It's easy to configure by specifying the data location, defining table schema, and querying using standard SQL.

Overall, Athena simplifies querying data in S3 using SQL, making it accessible and efficient for data analysis tasks.

[Lesson Resources](https://github.com/ACloudGuru-Resources/course-aws-certified-developer-associate/tree/main/Athena_Demo)

# S3 Summary
1. **S3 Basics**:
    - S3 is object-based storage for storing files in AWS.
    - Suitable for images, videos, code, documents, etc.
    - Files are stored in buckets with a unique name space.
2. **S3 URLs**:
    - S3 URLs include the bucket name, region, and key name (object/file name).
3. **S3 Object Components**:
    - Key: Object name.
    - Value: Data content in bytes.
    - Version ID: Supports multiple versions of objects.
    - Metadata: Data about stored data (e.g., content type, modification date).
4. **S3 Storage Classes**:
    - S3 Standard: Default for most workloads.
    - S3 Standard-IA: Infrequently accessed critical data.
    - S3 One Zone-IA: Infrequently accessed noncritical data in one zone.
    - Glacier Instant Retrieval: Archiving with millisecond retrieval.
    - Glacier Flexible Retrieval: Archiving with few hours retrieval.
    - Glacier Deep Archive: Rarely accessed data with long retrieval.
    - S3 Intelligent-Tiering: Automatic tiering based on access patterns.
5. **S3 Security**:
    - Default buckets are private.
    - Access control via bucket policies.
    - Access logs for auditing.
6. **S3 Encryption**:
    - Encryption in transit (SSL/TLS).
    - Encryption at rest (SSE-S3, SSE-KMS, SSE-C).
    - Client-side encryption for user-managed keys.
7. **Cross-Origin Resource Sharing (CORS)**:
    - Allows code in one bucket to access another bucket.
8. **CloudFront**:
    - Improves website performance via caching at edge locations.
    - Edge location, origin, and distribution concepts.
    - S3 Transfer Acceleration for faster uploads.
    - CloudFront AllowedMethods for defining HTTP methods.
9. **Certificate Management**:
    - AWS Certificate Manager for SSL/TLS certificates.
    - Certificates created in US-East-1 for CloudFront.
10. **Athena**:
    - Interactive query service for S3 data using SQL.
    - Serverless, no infrastructure configuration needed.

This summary covers the key points about S3, its features, security, encryption, CORS, CloudFront, certificate management, and Athena for querying S3 data using SQL.

[S3 FAQ](https://aws.amazon.com/s3/faqs/)

# Quiz

![1](Quiz/S3/1.png) 
![2](Quiz/S3/2.png) 
![3](Quiz/S3/3.png) 
![4](Quiz/S3/4.png) 
![5](Quiz/S3/5.png) 
![6](Quiz/S3/6.png) 
![7](Quiz/S3/7.png) 
![8](Quiz/S3/8.png) 
![9](Quiz/S3/9.png) 
![10](Quiz/S3/10.png) 
![11](Quiz/S3/11.png) 
![12](Quiz/S3/13.png) 
![13](Quiz/S3/12.png) 
![14](Quiz/S3/14.png) 
![15](Quiz/S3/15.png) 
![16](Quiz/S3/16.png) 
![17](Quiz/S3/17.png) 
![18](Quiz/S3/18.png) 
![19](Quiz/S3/19.png) 
![20](Quiz/S3/20.png) 
![21](Quiz/S3/21.png)